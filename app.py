import os
from dotenv import load_dotenv
from flask import Flask, render_template, request, jsonify, session
import google.generativeai as genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
import markdown
import uuid

load_dotenv()

app = Flask(__name__)
app.secret_key = os.urandom(24)

# Google API YapÄ±landÄ±rmasÄ±
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
if not GOOGLE_API_KEY:
    raise ValueError("âŒ GOOGLE_API_KEY bulunamadÄ±! .env dosyasÄ±nÄ± kontrol edin.")

genai.configure(api_key=GOOGLE_API_KEY)

# Global deÄŸiÅŸkenler
vectorstore = None
user_chains = {}

def load_vector_database():
    """Ã–nceden oluÅŸturulmuÅŸ Chroma veritabanÄ±nÄ± yÃ¼kle"""
    global vectorstore
    
    try:
        embeddings = GoogleGenerativeAIEmbeddings(
            model="models/text-embedding-004",
            google_api_key=GOOGLE_API_KEY
        )
        
        vectorstore = Chroma(
            persist_directory="chroma_db",
            embedding_function=embeddings,
            collection_name="gaih_qa"
        )
        
        print("âœ… VektÃ¶r veritabanÄ± baÅŸarÄ±yla yÃ¼klendi")
        return True
    except Exception as e:
        print(f"âŒ VektÃ¶r veritabanÄ± yÃ¼kleme hatasÄ±: {e}")
        return False

def create_qa_chain_for_user():
    """Her kullanÄ±cÄ± iÃ§in RAG tabanlÄ± soru-cevap zinciri oluÅŸtur"""
    global vectorstore
    
    if vectorstore is None:
        raise Exception("VektÃ¶r veritabanÄ± yÃ¼klenmemiÅŸ!")
    
    try:
        # LLM yapÄ±landÄ±rmasÄ±
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-exp",
            temperature=0.57,
            google_api_key=GOOGLE_API_KEY,
            convert_system_message_to_human=True
        )
        
        # Memory yapÄ±landÄ±rmasÄ±
        memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            output_key="answer"
        )
        
        # RAG chain
        qa_chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 10}
            ),
            memory=memory,
            return_source_documents=True,
            verbose=False
        )
        
        print("âœ… KullanÄ±cÄ± iÃ§in QA Chain oluÅŸturuldu")
        return qa_chain
    except Exception as e:
        print(f"âŒ QA Chain oluÅŸturma hatasÄ±: {e}")
        return None

@app.route('/')
def index():
    """Ana sayfa"""
    if 'user_id' not in session:
        session['user_id'] = str(uuid.uuid4())
    return render_template('index.html')

@app.route('/chat', methods=['POST'])
def chat():
    """Chatbot endpoint - KullanÄ±cÄ± mesajÄ±nÄ± iÅŸle"""
    try:
        data = request.get_json()
        user_message = data.get('message', '').strip()
        user_id = session.get('user_id', str(uuid.uuid4()))
        
        if not user_message:
            return jsonify({
                'error': 'LÃ¼tfen bir mesaj yazÄ±n'
            }), 400
        
        # KullanÄ±cÄ± iÃ§in chain yoksa oluÅŸtur
        if user_id not in user_chains:
            user_chains[user_id] = create_qa_chain_for_user()
            if user_chains[user_id] is None:
                return jsonify({'error': 'Asistan hazÄ±rlanamadÄ±'}), 500
        
        qa_chain = user_chains[user_id]
        
        # RAG ile cevap Ã¼ret
        response = qa_chain({"question": user_message})
        
        bot_answer = response['answer']
        source_docs = response.get('source_documents', [])
        
        # Markdown'Ä± HTML'e Ã§evir
        bot_answer_html = markdown.markdown(
            bot_answer,
            extensions=['extra', 'codehilite', 'nl2br']
        )
        
        # Kaynak bilgisi ekle
        source_info = []
        for i, doc in enumerate(source_docs[:3], 1):
            source_info.append({
                'id': i,
                'content': doc.page_content[:200] + "...",
                'metadata': doc.metadata
            })
        
        return jsonify({
            'success': True,
            'answer': bot_answer,
            'answer_html': bot_answer_html,
            'sources': source_info,
            'user_id': user_id
        })
        
    except Exception as e:
        print(f"âŒ Chat hatasÄ±: {e}")
        return jsonify({
            'error': f'Bir hata oluÅŸtu: {str(e)}'
        }), 500

@app.route('/clear', methods=['POST'])
def clear_history():
    """KonuÅŸma geÃ§miÅŸini temizle"""
    try:
        user_id = session.get('user_id')
        if user_id and user_id in user_chains:
            del user_chains[user_id]
        
        return jsonify({
            'success': True,
            'message': 'KonuÅŸma geÃ§miÅŸi temizlendi'
        })
    except Exception as e:
        return jsonify({
            'error': str(e)
        }), 500

@app.route('/health')
def health_check():
    """SaÄŸlÄ±k kontrolÃ¼ endpoint"""
    return jsonify({
        'status': 'healthy',
        'vectorstore': vectorstore is not None,
        'active_users': len(user_chains)
    })

# Uygulama baÅŸlangÄ±cÄ±nda vektÃ¶r veritabanÄ±nÄ± yÃ¼kle
with app.app_context():
    print("ğŸš€ Global AI Hub Chatbot baÅŸlatÄ±lÄ±yor...")
    if load_vector_database():
        print("âœ… Chatbot hazÄ±r!")
    else:
        print("âš ï¸ VektÃ¶r veritabanÄ± yÃ¼klenemedi!")

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)